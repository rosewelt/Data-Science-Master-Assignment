{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56c1938",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?\n",
    "\n",
    "Overfitting is an undesirable machine learning behavior that occurs when the machine learning model gives accurate predictions for training data but not for new data.\n",
    "\n",
    "Underfitting is another type of error that occurs when the model cannot determine a meaningful relationship between the input and output data. \n",
    "\n",
    "Underfit models experience high bias—they give inaccurate results for both the training data and test set. On the other hand, overfit models experience high variance—they give accurate results for the training set but not for the test set.\n",
    "\n",
    "Techniques to Reduce Underfitting\n",
    "Increase model complexity.\n",
    "Increase the number of features, performing feature engineering.\n",
    "Remove noise from the data.\n",
    "Increase the number of epochs or increase the duration of training to get better results.\n",
    "\n",
    "Techniques to Reduce Overfitting\n",
    "Increase training data.\n",
    "Reduce model complexity.\n",
    "Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "Ridge Regularization and Lasso Regularization.\n",
    "Use dropout for neural networks to tackle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a5c7c",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief\n",
    "\n",
    "Techniques to Reduce Overfitting Increase training data. Reduce model complexity. Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training). Ridge Regularization and Lasso Regularization. Use dropout for neural networks to tackle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881dd7f",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "    \n",
    "    Overfitting happens when:\n",
    "\n",
    "The training data is not cleaned and contains some “garbage”     values. The model captures the noise in the training data and fails to generalize the model's learning.\n",
    "The model has a high variance.\n",
    "The training data size is insufficient, and the model trains on the limited training data for several epochs.\n",
    "The architecture of the model has several neural layers bundled together. Deep neural networks are complex and require a significant amount of time to train, and often lead to overfitting the training set.\n",
    "Incorrect tuning of hyperparameters in the training phase leads to over-observing the training set, resulting in memorizing features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029dba41",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n",
    "\n",
    "If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it’s going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data.\n",
    "\n",
    "This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd6da67",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "Overfitting is easy to diagnose with the accuracy visualizations you have available. If \"Accuracy\" (measured against the training set) is very good and \"Validation Accuracy\" (measured against a validation set) is not as good, then your model is overfitting.\n",
    "\n",
    "Underfitting is the opposite counterpart of overfitting wherein your model exhibits high bias. This situation can occur when your model is not sufficiently complex to capture the relationship between features and labels (or if your model is too strictly regularized).\n",
    "\n",
    "Underfitting is a bit harder to diagnose. If Accuracy and Validation Accuracy are similar but are both poor, then you may be underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921708d",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "\n",
    "A high bias model has the following characteristics\n",
    "Failure to gather proper data trends.\n",
    "Possibility of having an improper fit.\n",
    "More generic and simplistic in an excessive degree.\n",
    "A high frequency of errors.\n",
    "\n",
    "A high variance model has the following characteristics −\n",
    "The presence of noise in the data set\n",
    "There is a possibility of overfitting.\n",
    "Complex models.\n",
    "Making an effort to bring all of the data points as close together as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12486b2d",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "\n",
    "Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, avoiding the risk of Overfitting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
